{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/ruyogagp/medical_interpretability')\n",
    "import numpy as np\n",
    "from pysurvival.models import BaseModel\n",
    "from pysurvival import utils\n",
    "import scipy\n",
    "import pandas as pandas\n",
    "import copy\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from source.utils import create_correlated_var\n",
    "from pysurvival.models.simulations import SimulationModel\n",
    "from lifelines import CoxPHFitter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from cga import cga\n",
    "from itertools import cycle\n",
    "import tqdm as tqdm\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Helper Functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "def fit_coxph(df):\n",
    "    cph = CoxPHFitter()\n",
    "    cph.fit(df, 'time', 'event')\n",
    "    cph.print_summary()\n",
    "\n",
    "def fit_coxph_norm(df):\n",
    "    standard_scaler = StandardScaler()\n",
    "    for col in df.columns:\n",
    "        if col == 'time' or col == 'event':\n",
    "            pass\n",
    "        df[col] = standard_scaler.fit_transform(df[[col]])\n",
    "    cph = CoxPHFitter()\n",
    "    cph.fit(df, 'time', 'event')\n",
    "    cph.print_summary()\n",
    "\n",
    "\n",
    "def save_orig(df, name, output_dir):\n",
    "    train, valid = train_test_split(df, test_size=0.3)\n",
    "    train.to_csv(\n",
    "        f\"{output_dir}/{name}_train.csv\",\n",
    "        index=False,\n",
    "    )\n",
    "    valid.to_csv(\n",
    "        f\"{output_dir}/{name}_valid.csv\",\n",
    "        index=False,\n",
    "    )\n",
    "    print(f\"Saved {output_dir}/{name}_train.csv\")\n",
    "    print(f\"Saved {output_dir}/{name}_valid.csv\")\n",
    "\n",
    "def df2csv(\n",
    "        df: pd.DataFrame,\n",
    "        name: str,\n",
    "        output_dir: str,\n",
    "):\n",
    "    \"\"\"\n",
    "    Writes csv given a dataframe + name\n",
    "    \"\"\"\n",
    "    train, valid = train_test_split(df, test_size=0.3)\n",
    "    train.to_csv(\n",
    "        f\"{output_dir}/{name}_train_details.csv\",\n",
    "        index=False,\n",
    "    )\n",
    "    valid.to_csv(\n",
    "        f\"{output_dir}/{name}_valid_details.csv\",\n",
    "        index=False,\n",
    "    )\n",
    "\n",
    "    train_df = train.loc[:, ['x_orig', 'y_orig', 'time_orig', 'event_orig']]\n",
    "    valid_df = valid.loc[:, ['x_orig', 'y_orig', 'time_orig', 'event_orig']]\n",
    "    train_df.rename(columns=dict(x_orig='x',\n",
    "                                 y_orig='y',\n",
    "                                 time_orig='time',\n",
    "                                 event_orig='event'), inplace=True)\n",
    "\n",
    "    valid_df.rename(columns=dict(x_orig='x',\n",
    "                                 y_orig='y',\n",
    "                                 time_orig='time',\n",
    "                                 event_orig='event'), inplace=True)\n",
    "    train_df.to_csv(\n",
    "        f\"{output_dir}/{name}_train.csv\",\n",
    "        index=False,\n",
    "    )\n",
    "    valid_df.to_csv(\n",
    "        f\"{output_dir}/{name}_valid.csv\",\n",
    "        index=False,\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simulation Model with correlations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "class SimulationModelWithCorrelations(SimulationModel):\n",
    "    \"\"\"\n",
    "    Subclasses `SimulationModel` to generated data from an predefined\n",
    "    risk factor.\n",
    "    \"\"\"\n",
    "\n",
    "    def generate_data(self,\n",
    "                      df: pd.DataFrame,\n",
    "                      feature_weights: list,\n",
    "                      feature_names: list,\n",
    "                      ):\n",
    "\n",
    "        def risk_function(x_std, feature_weights):\n",
    "            \"\"\" Calculating the risk function based on the given risk type \"\"\"\n",
    "\n",
    "            # Dot product\n",
    "            risk = np.dot(x_std, feature_weights )\n",
    "\n",
    "            # Choosing the type of risk\n",
    "            if self.risk_type.lower() == 'linear' :\n",
    "                return risk.reshape(-1, 1)\n",
    "\n",
    "            elif self.risk_type.lower() == 'square' :\n",
    "                risk = np.square(risk*self.risk_parameter)\n",
    "\n",
    "\n",
    "            elif self.risk_type.lower() == 'gaussian' :\n",
    "                risk = np.square(risk)\n",
    "                risk = np.exp( - risk*self.risk_parameter)\n",
    "\n",
    "            return risk.reshape(-1, 1)\n",
    "\n",
    "        input_data = df.loc[:, feature_names].to_numpy()\n",
    "        self.dataset = copy.deepcopy(df)\n",
    "        num_samples = input_data.shape[0]\n",
    "        X_std = self.scaler.fit_transform(input_data)\n",
    "        BX = risk_function(X_std, feature_weights)\n",
    "\n",
    "        # Building the survival times\n",
    "        T = self.time_function(BX)\n",
    "        C = np.random.normal(loc=self.censored_parameter, scale=5, size=num_samples)\n",
    "        C = np.maximum(C, 0.0)\n",
    "        time = np.minimum(T, C)\n",
    "        E = 1.0 * (T == time)\n",
    "\n",
    "        # Building dataset\n",
    "        self.dataset = copy.deepcopy(df)\n",
    "        self.dataset['time'] = time\n",
    "        self.dataset['event'] = E\n",
    "\n",
    "        # Building the time axis and time buckets\n",
    "        self.times = np.linspace(0.0, max(self.dataset[\"time\"]), self.bins)\n",
    "        self.get_time_buckets()\n",
    "\n",
    "        # Building baseline functions\n",
    "        self.baseline_hazard = self.hazard_function(self.times, 0)\n",
    "        self.baseline_survival = self.survival_function(self.times, 0)\n",
    "\n",
    "        # Printing summary message\n",
    "        message_to_print = \"Number of data-points: {} - Number of events: {}\"\n",
    "        print(message_to_print.format(num_samples, sum(E)))\n",
    "        return self.dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Correlation Case Graph"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "@cga.node\n",
    "def correlate(x: float, rnorm_vector:float, noise:float) -> float:\n",
    "    \"\"\"\n",
    "    :param x: exisiting data to correlate\n",
    "    :param coeff: correlation coefficient\n",
    "    :param noise: noise variable\n",
    "    :return: variable correlated by coeff to the exisiting variable x\n",
    "    \"\"\"\n",
    "    correlate = create_correlated_var(x, rnorm_vector,\n",
    "                                      mu=np.mean(x),\n",
    "                                      sd=np.std(x),\n",
    "                                      empirical=True,\n",
    "                                      r=-0.75)\n",
    "    return correlate + noise\n",
    "\n",
    "@cga.node\n",
    "def sample_random_normal(noise:float)->float:\n",
    "    \"\"\"\n",
    "    :param n: sample size\n",
    "    :param noise: noise variable\n",
    "    :return: random normal variable\n",
    "    \"\"\"\n",
    "    return np.random.normal(size=100) + noise\n",
    "\n",
    "@cga.node\n",
    "def correlation_coefficient(coeff:float) -> float:\n",
    "    return coeff\n",
    "\n",
    "class CorrelationCaseGraph(cga.Graph):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        causal graph for correlation case\n",
    "        :param n: number of data points\n",
    "        :param coeff: desired correlation coefficient between the two variables\n",
    "        \"\"\"\n",
    "        noise = cga.node(lambda: np.random.normal(scale=0.0001, size=100))\n",
    "        rnorm_vector = cga.node(lambda: np.random.normal(size=100))\n",
    "        self.rnorm = rnorm_vector(name=\"rnorm\")\n",
    "        self.noise_x = noise(name=\"noise_x\")\n",
    "        self.noise_y = noise(name=\"noise_y\")\n",
    "        self.x = sample_random_normal(self.noise_x, name='x')\n",
    "        self.y = correlate(self.x, self.rnorm, self.noise_y, name='y')\n",
    "        super().__init__([self.x, self.y])\n",
    "\n",
    "    def get_interventions(self,\n",
    "                          sim: SimulationModelWithCorrelations,\n",
    "                          n_iterations: int,\n",
    "                          feature_weights: list,\n",
    "                          ) -> pd.DataFrame:\n",
    "        data = None\n",
    "        for node in [self.noise_x, self.noise_y]:\n",
    "            for _ in tqdm.trange(n_iterations, desc=f\"Intervention {node.name}\"):\n",
    "                # resample noise\n",
    "                orig, intervention = self.sample_do(action=cga.Resample(node))\n",
    "                row = {'modified_attribute': [node.name] * 100}\n",
    "                # add orig + do to the dictionary\n",
    "                row.update({\n",
    "                    n.name + \"_orig\": v\n",
    "                    for n, v in orig.items()\n",
    "                })\n",
    "                row.update({\n",
    "                    n.name + \"_do\": v\n",
    "                    for n, v in intervention.items()\n",
    "                })\n",
    "\n",
    "                data = row if data is None else data\n",
    "                for key in row.keys():\n",
    "                    row[key] = row[key].tolist() if isinstance(row[key], np.ndarray) else row[key]\n",
    "                    data[key].extend(row[key])\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        orig_cols = ['x_orig', 'y_orig']\n",
    "        orig_df = sim.generate_data(df, feature_names=orig_cols,\n",
    "                                    feature_weights=feature_weights)\n",
    "\n",
    "        xdf = orig_df.loc[orig_df.modified_attribute=='noise_x']\\\n",
    "            .loc[:, ['x_orig', 'y_orig', 'time', 'event']]\\\n",
    "            .rename(columns=dict(x_orig='x', y_orig='y'))\n",
    "        ydf = orig_df.loc[orig_df.modified_attribute=='noise_y']\\\n",
    "            .loc[:, ['x_orig', 'y_orig', 'time', 'event']]\\\n",
    "            .rename(columns=dict(x_orig='x', y_orig='y'))\n",
    "\n",
    "        df['event_orig'] = orig_df.event\n",
    "        df['time_orig'] = orig_df.time\n",
    "\n",
    "        do_cols = ['x_do', 'y_do']\n",
    "        do_df = sim.generate_data(df, feature_names=do_cols,\n",
    "                                  feature_weights=feature_weights)\n",
    "        df['event_do'] = do_df.event\n",
    "        df['time_do'] = do_df.time\n",
    "\n",
    "        return xdf, ydf, df\n",
    "\n",
    "    def test_intervention(self, n_iterations):\n",
    "        for node in [self.noise_x, self.noise_y]:\n",
    "            for _ in tqdm.trange(n_iterations, desc=f\"Intervention {node.name}\"):\n",
    "                # resample noise\n",
    "                orig, intervention0, intervention1, intervention2 = self.sample_do(action=cga.Resample(node))\n",
    "        return orig, intervention0, intervention1, intervention2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sample from Graph"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling: 100%|██████████| 100/100 [00:00<00:00, 623.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data-points: 10100 - Number of events: 7968.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "              x         y      time     event\nx      1.000000 -0.733541 -0.138720  0.010682\ny     -0.733541  1.000000  0.051837  0.008678\ntime  -0.138720  0.051837  1.000000  0.812486\nevent  0.010682  0.008678  0.812486  1.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x</th>\n      <th>y</th>\n      <th>time</th>\n      <th>event</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>x</th>\n      <td>1.000000</td>\n      <td>-0.733541</td>\n      <td>-0.138720</td>\n      <td>0.010682</td>\n    </tr>\n    <tr>\n      <th>y</th>\n      <td>-0.733541</td>\n      <td>1.000000</td>\n      <td>0.051837</td>\n      <td>0.008678</td>\n    </tr>\n    <tr>\n      <th>time</th>\n      <td>-0.138720</td>\n      <td>0.051837</td>\n      <td>1.000000</td>\n      <td>0.812486</td>\n    </tr>\n    <tr>\n      <th>event</th>\n      <td>0.010682</td>\n      <td>0.008678</td>\n      <td>0.812486</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample features\n",
    "data = None\n",
    "correlation_graph = CorrelationCaseGraph()\n",
    "for _ in tqdm.trange(100, desc='sampling'):\n",
    "    result = correlation_graph.sample()\n",
    "    data = result if data is None else data\n",
    "    for key in result.keys():\n",
    "        result[key] = result[key].tolist() if isinstance(result[key], np.ndarray) else result[key]\n",
    "        data[key].extend(result[key])\n",
    "del data[correlation_graph.noise_x]\n",
    "del data[correlation_graph.noise_y]\n",
    "del data[correlation_graph.rnorm]\n",
    "\n",
    "# Generate data\n",
    "training_features = pd.DataFrame(data)\n",
    "sim = SimulationModelWithCorrelations(risk_type='linear', alpha=1.0, beta=5.0, censored_parameter=5.0, survival_distribution='weibull')\n",
    "feature_weights = [np.log(2), np.log(1.5)]\n",
    "feature_names = [correlation_graph.x, correlation_graph.y]\n",
    "training_df = sim.generate_data(training_features, feature_weights=feature_weights, feature_names=feature_names)\n",
    "\n",
    "# Check correlations\n",
    "training_df.corr()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save Training Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /data/analysis/ag-reils/ag-reils-shared/cardioRS/data/interpretability/correlation/p-0.75_train.csv\n",
      "Saved /data/analysis/ag-reils/ag-reils-shared/cardioRS/data/interpretability/correlation/p-0.75_valid.csv\n"
     ]
    }
   ],
   "source": [
    "directory = '/data/analysis/ag-reils/ag-reils-shared/cardioRS/data/interpretability/correlation'\n",
    "save_orig(training_df, name='p-0.75', output_dir=directory)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Resample Features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intervention noise_x: 100%|██████████| 50/50 [00:00<00:00, 350.33it/s]\n",
      "Intervention noise_y: 100%|██████████| 50/50 [00:00<00:00, 332.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data-points: 10100 - Number of events: 8016.0\n",
      "Number of data-points: 10100 - Number of events: 8057.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "              x         y      time     event\nx      1.000000 -0.730646 -0.148846  0.012297\ny     -0.730646  1.000000  0.046590 -0.010465\ntime  -0.148846  0.046590  1.000000  0.808448\nevent  0.012297 -0.010465  0.808448  1.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x</th>\n      <th>y</th>\n      <th>time</th>\n      <th>event</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>x</th>\n      <td>1.000000</td>\n      <td>-0.730646</td>\n      <td>-0.148846</td>\n      <td>0.012297</td>\n    </tr>\n    <tr>\n      <th>y</th>\n      <td>-0.730646</td>\n      <td>1.000000</td>\n      <td>0.046590</td>\n      <td>-0.010465</td>\n    </tr>\n    <tr>\n      <th>time</th>\n      <td>-0.148846</td>\n      <td>0.046590</td>\n      <td>1.000000</td>\n      <td>0.808448</td>\n    </tr>\n    <tr>\n      <th>event</th>\n      <td>0.012297</td>\n      <td>-0.010465</td>\n      <td>0.808448</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample from graph\n",
    "correlation_graph = CorrelationCaseGraph()\n",
    "feature_weights = [np.log(2), np.log(1.5)]\n",
    "sim = SimulationModelWithCorrelations(risk_type='linear', alpha=1.0, beta=5.0, censored_parameter=5.0, survival_distribution='weibull')\n",
    "xdf, ydf, resampling_df = correlation_graph.get_interventions(sim=sim, n_iterations=50, feature_weights=feature_weights)\n",
    "\n",
    "# Check correlations\n",
    "xdf.corr()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save Attribution Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "xdf.to_csv(f'{directory}/p-0.75_attribute_x.csv', index=False)\n",
    "ydf.to_csv(f'{directory}/p-0.75_attribute_y.csv', index=False)\n",
    "resampling_df.to_csv(f'{directory}/p-0.75_attribute_details.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}